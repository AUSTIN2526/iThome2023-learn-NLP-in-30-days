# iThome2023-learn-NLP-in-30-days
該專案主要帶你學習從0經驗的NLP新手到成為微調LLM的專家

## 文章簡介
近幾個月來，因ChatGPT的出現，推動了NLP領域的發展，因此在本次鐵人賽的挑戰中，我會通過這30天的時間來講述NLP領域中的熱門模型背後的技術原理(例如:Transformer、BERT、GPT)，並從實際的應用中，告訴你該怎麼撰寫這些模型的程式碼，以加深我們對該模型的印象。同時我會還會使用不同的工具，來分析這些文字之間的關聯性，並對此結果加以解釋，從而一步步的理解NLP模型中的共同之處與運算方式。

## 書籍宣傳
* [【Day 1】學習NLP前我們應該要準備什麼?](https://ithelp.ithome.com.tw/articles/10317977)
* [【Day 2】電腦該怎麼理解人類的語言 (上) - 文字怎麼輸入到模型中](https://ithelp.ithome.com.tw/articles/10318965)
* [【Day 3】電腦該怎麼理解人類的語言 (下) - 模型理解文字的方式](https://ithelp.ithome.com.tw/articles/10321193)
* [【Day 4】Pytorch & TorchText的正確開啟方式](https://ithelp.ithome.com.tw/articles/10322104)
* [【Day 5】深度神經網路該怎麼改變Embedding向量(上)-揭密神經網路訓練的過程](https://ithelp.ithome.com.tw/articles/10323386)
* [【Day 6】深度神經網路該怎麼改變Embedding向量(下)-PyTorch訓練的策略和方法](https://ithelp.ithome.com.tw/articles/10323930)
* [【Day 7】文字也是一種有時間序列的資料(上)-時間序列模型大揭密](https://ithelp.ithome.com.tw/articles/10324660)
* [【Day 8】文字也是一種有時間序列的資料(下)-用IMDB影評探索文字中的情緒](https://ithelp.ithome.com.tw/articles/10324839)
* [【Day 9】掌握文字翻譯的技術(上)-Seq2Seq與時間序列模型](https://ithelp.ithome.com.tw/articles/10326701)
* [【Day 10】掌握文字翻譯的技術(中)-為何需要注意力機制](https://ithelp.ithome.com.tw/articles/10327536)
* [【Day 11】掌握文字翻譯的技術(下)-英法語言翻譯模型](https://ithelp.ithome.com.tw/articles/10328763)
* [【Day 12】該如何選擇損失函數與激勵函數?中文該如何斷詞?](https://ithelp.ithome.com.tw/articles/10329094)
* [【Day 13】預訓練模型的強大之處? 我們要怎麼使用它?](https://ithelp.ithome.com.tw/articles/10330137)
* [​【Day 14】​解析詞嵌入預訓練模型的奧秘(上)-深度探索Word2Vec的奧妙之處](https://ithelp.ithome.com.tw/articles/10330450)
* [​【Day 15】​解析詞嵌入預訓練模型的奧秘(中)-全域統計的重要性GloVe技術解析](https://ithelp.ithome.com.tw/articles/10331153)
* [【Day 16】解析詞嵌入預訓練模型的奧秘(下)-fastText中Subword建立的重要性](https://ithelp.ithome.com.tw/articles/10332218)
* [【Day 17】解析詞嵌入預訓練模型的奧秘(終)-利用預先訓練的詞嵌入來保護隱私](https://ithelp.ithome.com.tw/articles/10332582)
* [【Day 18】會根據上下文改變的詞嵌入向量 (上) - 預訓練模型ELMo震撼登場](https://ithelp.ithome.com.tw/articles/10333583)
* [【Day 19】會根據上下文改變的詞嵌入向量 (下) - ELMo該如何使用與Embedding可視化](https://ithelp.ithome.com.tw/articles/10334221)
* [【Day 20】萬物皆可Transformer(上)-Transformer中所使用的技巧解析](https://ithelp.ithome.com.tw/articles/10334540)
* [【Day 21】萬物皆可Transformer(下) - 使用Transformer找出文本中重要的訊息](https://ithelp.ithome.com.tw/articles/10335390)
* [【Day 22】因為站在巨人的肩膀上才能眺望更遠的風景(上)-BERT的出現與溫故知新的重要性](https://ithelp.ithome.com.tw/articles/10335931)
* [【Day 23】因為站在巨人的肩膀上才能眺望更遠的風景(下)-使用SQuAD做QA問答](https://ithelp.ithome.com.tw/articles/10336290)
* [【Day 24】用暴力美學屹立於不敗之地(上) - GPT家族的霸道之路](https://ithelp.ithome.com.tw/articles/10337089)
* [【Day 25】用暴力美學屹立於不敗之地(下) - 用GPT-J來告訴你大型語言模型該如何用LoRA微調](https://ithelp.ithome.com.tw/articles/10337638)
* [【Day 26】當今最強大的SOTA模型ChatGPT(上)-prompt?instruction?RLHF?](https://ithelp.ithome.com.tw/articles/10338188)
* [【Day 27】當今最強大的SOTA模型ChatGPT(下)-讓ChatGPT成為你的私人助理](https://ithelp.ithome.com.tw/articles/10338444)
* [【Day 28】ChatGPT的挑戰者LLaMA(上) - 目前最強大的開源語言模型LLaMA究竟做了什麼](https://ithelp.ithome.com.tw/articles/10338745)
* [【Day 29】ChatGPT的挑戰者LLaMA(下) - 用RLHF與QLoRA調整大型語言模型](https://ithelp.ithome.com.tw/articles/10339382)
* [【Day 30】自然語言處理的旅程總結與未來學習方向](https://ithelp.ithome.com.tw/articles/10339616)

## 教學網址
[30天內成為NLP大師：掌握關鍵工具和技巧](https://ithelp.ithome.com.tw/users/20152236/ironman/6669?page=1) 系列



