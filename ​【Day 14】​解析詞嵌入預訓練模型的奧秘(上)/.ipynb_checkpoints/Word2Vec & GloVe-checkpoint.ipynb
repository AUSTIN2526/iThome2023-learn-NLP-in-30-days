{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f6b442e-720d-4b06-9650-66aa885dfe1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class SkipGram(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, output):\n",
    "        super().__init__()\n",
    "        self.emb_in = nn.Embedding(vocab_size, embed_size)\n",
    "        self.emb_out = nn.Embedding(vocab_size, embed_size)\n",
    "        self.L_in = nn.Linear(embed_size, output)\n",
    "        self.L_out = nn.Linear(embed_size, output)\n",
    "        \n",
    "    def forward(self, target, context):\n",
    "        in_embeds = self.emb_in(target)\n",
    "        out_embeds = self.emb_out(context)\n",
    "        \n",
    "        return self.L_in(in_embeds) + self.L_out(out_embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41630313-06ac-4235-a5f4-86f58efd81a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.9042],\n",
      "        [1.4628]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "vocab_size = 1000  #假設有1000個詞彙\n",
    "embed_size = 100\n",
    "output = 1\n",
    "model = SkipGram(vocab_size, embed_size, output)\n",
    "\n",
    "\n",
    "target_word_index = 42             # 目標詞彙的索引\n",
    "context_word_index = [17, 23]      # 上下文索引\n",
    "\n",
    "# 轉換\n",
    "target = torch.tensor(target_word_index, dtype=torch.long)\n",
    "context = torch.tensor(context_word_index, dtype=torch.long)\n",
    "\n",
    "# 計算輸出\n",
    "output_score = model(target, context)\n",
    "print(output_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65b74682-86d8-48fc-a6a5-f3de72ef577f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkipGram(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size):\n",
    "        super().__init__()\n",
    "        self.emb_in = nn.Embedding(vocab_size, embed_size)\n",
    "        self.emb_out = nn.Embedding(vocab_size, embed_size)\n",
    "       \n",
    "    def forward(self, target, context):\n",
    "        in_embeds = self.emb_in(target)\n",
    "        out_embeds = self.emb_out(context)\n",
    "        \n",
    "        return torch.matmul(in_embeds, out_embeds.t())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c187c21-d707-440d-915c-5be9423f5957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -3.2610, -20.0314], grad_fn=<SqueezeBackward4>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "vocab_size = 1000  #假設有1000個詞彙\n",
    "embed_size = 100\n",
    "model = SkipGram(vocab_size, embed_size)\n",
    "\n",
    "\n",
    "target_word_index = 42             # 目標詞彙的索引\n",
    "context_word_index = [17, 23]      # 上下文索引\n",
    "\n",
    "# 轉換\n",
    "target = torch.tensor(target_word_index, dtype=torch.long)\n",
    "context = torch.tensor(context_word_index, dtype=torch.long)\n",
    "\n",
    "# 計算輸出\n",
    "output_score = model(target, context)\n",
    "print(output_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38e03872-c168-4bd9-bc2c-1c93fb262e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkipGram(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size):\n",
    "        super().__init__()\n",
    "        self.emb_in = nn.Embedding(vocab_size, embed_size)\n",
    "        self.emb_out = nn.Embedding(vocab_size, embed_size)\n",
    "        \n",
    "    def forward(self, target, context):\n",
    "        in_embeds = self.emb_in(target)\n",
    "        out_embeds = self.emb_out(context)\n",
    "        matmul_emb = torch.matmul(in_embeds, out_embeds.t())\n",
    "       \n",
    "        return nn.functional.softmax(matmul_emb.view(1, -1), dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "494216f4-3f7e-4f74-9608-c819f16bd9bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0030, 0.9970]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 1000  #假設有1000個詞彙\n",
    "embed_size = 100\n",
    "output = 1\n",
    "model = SkipGram(vocab_size, embed_size)\n",
    "\n",
    "\n",
    "target_word_index = 42             # 目標詞彙的索引\n",
    "context_word_index = [17, 23]      # 上下文索引\n",
    "\n",
    "# 轉換\n",
    "target = torch.tensor(target_word_index, dtype=torch.long)\n",
    "context = torch.tensor(context_word_index, dtype=torch.long)\n",
    "\n",
    "# 計算輸出\n",
    "output_score = model(target, context)\n",
    "print(output_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30cfa746-09c6-4786-b5f9-2d7b27e424ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBOWModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, output):\n",
    "        super().__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.linear = nn.Linear(embedding_dim, output)\n",
    "\n",
    "    def forward(self, context):\n",
    "        embedded = self.embeddings(context)\n",
    "        summed = torch.sum(embedded, dim=0)\n",
    "        output = self.linear(summed)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e649eb9a-5ab9-471c-9372-a3983e28ecf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.7934], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "vocab_size = 100\n",
    "embedding_dim = 100\n",
    "output = 1\n",
    "\n",
    "#根據Windows取得的context\n",
    "context = torch.tensor([1, 5, 32, 4, 2])\n",
    "\n",
    "model = CBOWModel(vocab_size, embedding_dim, output)\n",
    "\n",
    "# 使用模型进行前向传播\n",
    "output = model(context)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37a530c0-ad43-480c-854e-0111031175ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBOWModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, output):\n",
    "        super().__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.linear = nn.Linear(embedding_dim, output)\n",
    "\n",
    "    def forward(self, context):\n",
    "        embedded = self.embeddings(context)\n",
    "        summed = torch.mean(embedded, dim=0)\n",
    "        output = self.linear(summed)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e5713a1-3fc1-4f33-add4-cfeaf20fd84e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0416], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "vocab_size = 100\n",
    "embedding_dim = 100\n",
    "output = 1\n",
    "\n",
    "#根據Windows取得的context\n",
    "context = torch.tensor([1, 5, 32, 4, 2])\n",
    "\n",
    "model = CBOWModel(vocab_size, embedding_dim, output)\n",
    "\n",
    "# 使用模型进行前向传播\n",
    "output = model(context)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "461a339d-0366-436d-9d2d-d9e62c34e260",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBOWModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super().__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.linear = nn.Linear(embedding_dim, 2)\n",
    "\n",
    "    def forward(self, context):\n",
    "        embedded = self.embeddings(context)\n",
    "        embedded_avg = embedded.mean(dim=0)\n",
    "        output = self.linear(embedded_avg)\n",
    "        return nn.functional.softmax(output.view(1, -1), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc06e322-e18f-45e9-bba9-bd33288f214e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3825, 0.6175]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "vocab_size = 100\n",
    "embedding_dim = 100\n",
    "\n",
    "#根據Windows取得的context\n",
    "context = torch.tensor([1, 5, 32, 4, 2])\n",
    "\n",
    "model = CBOWModel(vocab_size, embedding_dim)\n",
    "\n",
    "# 使用模型进行前向传播\n",
    "output = model(context)\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
